# Projeto de ComparaÃ§Ã£o de Modelos para InterpretaÃ§Ã£o Comparativa

Este projeto implementa um experimento comparativo entre trÃªs modelos de inferÃªncia textual para determinar qual apresenta melhor desempenho na identificaÃ§Ã£o de similaridade entre atividades operacionais. Os modelos analisados sÃ£o:

- **BERT** (`facebook/bart-large-mnli`)
- **RoBERTa** (`joeddav/xlm-roberta-large-xnli`)
- **DeBERTa** (`cross-encoder/nli-deberta-v3-large`)

Os experimentos utilizam a infraestrutura configurada em home (~), que abriga o ambiente de desenvolvimento e os modelos utilizados no ambiente atual.

## ğŸ“‚ Estrutura do LaboratÃ³rio
O laboratÃ³rio foi configurado conforme a seguinte estrutura:

```
~/ailabs/
â”œâ”€â”€ models/          # Modelos de IA
â”‚   â”œâ”€â”€ transformers/ # Modelos baseados em Transformer
â”œâ”€â”€ datasets/        # Conjuntos de dados
â”œâ”€â”€ workspaces/      # Projetos e experimentos
â”‚   â”œâ”€â”€ tsaI_experiments/  # DiretÃ³rio dos experimentos
â”œâ”€â”€ dependencies/    # DependÃªncias e ambientes virtuais
â”‚   â”œâ”€â”€ venvs/       # Ambientes virtuais Python
â”‚       â”œâ”€â”€ tsaI_env/  # Ambiente virtual Python para o experimento
```

## ğŸ› ï¸ PreparaÃ§Ã£o do Ambiente
### 1ï¸âƒ£ **Criando e ativando o ambiente virtual**
```bash
python3.12 -m venv ~/ailabs/dependencies/venvs/tsaI_env
source ~/ailabs/dependencies/venvs/tsaI_env/bin/activate
```

### 2ï¸âƒ£ **Instalando as dependÃªncias necessÃ¡rias**
```bash
pip install --upgrade pip
pip install torch torchvision torchaudio transformers datasets numpy scikit-learn matplotlib ipykernel
```

### 3ï¸âƒ£ **Download dos Modelos**
Na primeira execuÃ§Ã£o de cada experimento, os modelos serÃ£o baixados automaticamente pela biblioteca `transformers`. Para realizar o download manualmente e armazenar no cache local, execute:

```bash
python -c "from transformers import AutoModel, AutoTokenizer; \
            models = ['facebook/bart-large-mnli', 'joeddav/xlm-roberta-large-xnli', 'cross-encoder/nli-deberta-v3-large']; \
            [AutoModel.from_pretrained(m, cache_dir='~/ailabs/models/transformers/') for m in models]; \
            [AutoTokenizer.from_pretrained(m, cache_dir='~/ailabs/models/transformers/') for m in models]"
```

Isso garantirÃ¡ que os modelos estejam disponÃ­veis localmente para uso offline.

## ğŸš€ ConfiguraÃ§Ã£o no VSCode
1. Abra o diretÃ³rio do projeto no VSCode:
```bash
cd ~/ailabs/workspaces/tsaI_experiments
code .
```

2. Selecione o ambiente virtual no VSCode:
   - Pressione **Ctrl + Shift + P**
   - Pesquise por **"Python: Select Interpreter"**
   - Escolha o caminho:
     ```
     ~/ailabs/dependencies/venvs/tsaI_env/bin/python
     ```

Agora o ambiente estÃ¡ pronto para executar os experimentos com os diferentes modelos de inferÃªncia textual. ğŸš€

